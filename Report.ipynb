{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d5a012",
   "metadata": {},
   "source": [
    "# Final Project Report:\n",
    "## Galactic Distance Estimates from Photographs\n",
    "#### Author: Julieanna Bacon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1c74c",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Definitions](#def)\n",
    "1. [Problem Background](#introduction)\n",
    "2. [Project Overview](#paragraph1)\n",
    "    1. [Sub paragraph](#subparagraph1)\n",
    "3. [Another paragraph](#paragraph2)\n",
    "\n",
    "\n",
    "### Sub paragraph <a name=\"subparagraph1\"></a>\n",
    "This is a sub paragraph, formatted in heading 3 style\n",
    "\n",
    "## Another paragraph <a name=\"paragraph2\"></a>\n",
    "The second paragraph text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe16152",
   "metadata": {},
   "source": [
    "### Definitions <a name=\"def\"></a>\n",
    "- Redshift – “distance” as measured by Doppler shift. \n",
    "- Hubble Constant – a time varying parameter that tells us the rate of expansion of the universe at that time epoch \n",
    "- CCD – the camera of choice for most telescopes \n",
    "- Spectroscopic Redshift – more accurate than photometric redshifts. Distance measurements produced by fitting spectra data to a black body curve \n",
    "- Photometric Redshift - distance measurements produced by photometric data \n",
    "- Photometric – Data produced by photos of objects. Usually taken in a filter to only capture photos in a given range of wavelengths (red, blue, green, etc). \n",
    "- SDSS – Sloan Digital Sky Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f14b447",
   "metadata": {},
   "source": [
    "## Problem Background <a name=\"introduction\"></a>\n",
    "I used Luigi and salted graphs for data extraction, preprocessing, and experimentation while I replicated (and modified) the smaller architecture from this paper: Photometric redshifts from SDSS images using a Convolutional Neural Network. I also reference this one quite a lot in my discussion: Investigating Deep Learning Methods for Obtaining Photometric Redshift Estimations from Images.\n",
    "\n",
    "The overall goal of the project is to produce distance estimations of galaxies from photos in a learned approach. Below is a quick overview of the science behind why this is possible.\n",
    "\n",
    "How far away is this galaxy?\n",
    "\n",
    "<img src='docs/images/galaxy_dist.png' width=\"400\" height=\"400\">\n",
    "\n",
    "In astronomy, until we develop light speed engines, we’re almost entirely limited to estimating this by only cameras. It’s a surprisingly hard task that’s far from solved. It also underpins every aspect of research. From determining the age of the universe and resolving crises in fundamental physics to being able to calibrate solar convection models, it impacts everything.\n",
    "\n",
    "Astronomers have developed a variety of methods, used for different distances and different situations, but we will talk about the most accurate and its learned approximation.\n",
    "\n",
    "<img src='docs/images/slide1.png' width=\"700\" height=\"500\">  \n",
    "\n",
    "This method is called spectroscopic redshift. Spectroscopic, meaning it looks at the spectrum, and redshift, the distance to the galaxy. We’re all familiar with Doppler Shift, as we experience it every time an ambulance passes us on the street. It describes how waves, sound or light, get stretched out or compressed as objects move relative to each other. And galaxies are, unfortunately and fortunately, all moving away from us. This is because the universe itself is expanding, and like ants on a balloon being blown up, ants/galaxies farther away from us appear to moving faster away than nearby ants.\n",
    "\n",
    "<img src='docs/images/cosmic_doppler.png' width=\"400\" height=\"400\">  \n",
    "<!-- <img src='docs/images/cosmological_redshift.png' width=\"400\" height=\"400\"> \n",
    " -->\n",
    "With expansion, the light from galaxies is being stretched out, and the farther away from us, the more their light has been stretched out. This stretching out of light makes the whole object seem slightly redder (thus the term redshift). We can measure how the light has become stretched out, and thus how far away it is, through spectroscopy very precisely, as spectra shows us how bright the object is at every wavelength. If we know that the object will be super bright at wavelength 4268nm (for example) because it’s mostly made of hydrogen and hydrogen glows very brightly at that wavelength, we can see how much that hydrogen line has shifted when we observe the object.\n",
    "\n",
    "<img src='docs/images/spectra_elements.png' width=\"400\" height=\"400\"> \n",
    "\n",
    "Unfortunately, getting spectra is a hard process that’s not always possible.\n",
    "\n",
    "<img src='docs/images/slide2.png' width=\"700\" height=\"400\">  \n",
    "\n",
    "The alternative is to see how bright the image via photos, which you can think of as a rough histogram of a spectrum. Spectra show brightness at every wavelength, photographs show brightness over a range of wavelengths. Astronomers use filters, like green, ultraviolet, etc to take photos in narrower wavelength bands than our phone cameras to see how bright something is over that histogram bin. Since there’s still information about how the object has been “reddened” in that rough histogram, astronomers can still get a (rougher) estimate of that reddening. This process is called Photometric Redshift.\n",
    "Hubble Deep Field image with galaxy circled\n",
    "\n",
    "For photometric redshifts, most astronomy pipelines today transform a cleaned image of an object in a particular filter to a single number, magnitude/brightness, that can then be used in a machine learning approach. There are other things calculated from these images that are used in other situations, but for redshift estimation, the work is done with usually five or more magnitudes in different, non-overlapping filters.\n",
    "\n",
    "Like you see in the picture above, training directly on the images has struggled to be adopted as the go-to method for estimating distances not-from-spectra. That’s the motivation for this project, to built out an automated pipeline that I can continue to improve as the astronomy community finds better and better architectures for estimating redshifts from photos (I also want this pipeline to work on improving estimates myself as well!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e76068",
   "metadata": {},
   "source": [
    "## Project Overview <a name=\"paragraph1\"></a>\n",
    "\n",
    "The goal of this project is to produce distance estimates for galaxies via images of them in different filter bands.\n",
    "<!-- <img src='docs/images/sdss_filters.png' width=\"400\" height=\"400\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d817a5",
   "metadata": {},
   "source": [
    "## Data EDA\n",
    "visualization of distribution of redshifts, showing the raw images, how many classes should I start with for prediction for softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ef95f",
   "metadata": {},
   "source": [
    "## Steps to Improve Model <a name=\"improving\"></a>\n",
    "#### Data Augmentation:\n",
    "need to flip & rotate images as well. That can help go from ~8k images to ?? 16k?.\n",
    "Might want to equalize the pixels\n",
    "Experiments to try:\n",
    "- smaller architecture\n",
    "- smaller with mixed input\n",
    "- smaller with equalized images\n",
    "- smaller with mixed input and equalized images\n",
    "- compare with vanilla trianing on categorical cross entropy and epochs=25. \n",
    "\n",
    "Also did a custom loss function. The original paper's code used a sparse categorical cross entropy loss, which neglects what our \"categories\" really mean - since an estimate that's in a nearby bin is better than an estimate that's in a far away bin. \n",
    "\n",
    "I modified the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd7935",
   "metadata": {},
   "source": [
    "https://www.aanda.org/articles/aa/full_html/2019/01/aa33617-18/aa33617-18.html\n",
    "with screenshot in folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c2c37",
   "metadata": {},
   "source": [
    "# CURRENT WIP OF CODE AND DEV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a32c80",
   "metadata": {},
   "source": [
    "rotationally invariant, make sure no data leaks, do mixed-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71220d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading S3 module without the python package boto3. Will crash at runtime if S3 functionality is used.\n"
     ]
    }
   ],
   "source": [
    "from final_project import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd33faa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 6 required positional arguments: 'batch_size', 'test_split', 'num_classes', 'seed', 'lr', and 'input_img_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInceptionModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 6 required positional arguments: 'batch_size', 'test_split', 'num_classes', 'seed', 'lr', and 'input_img_shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811739e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
